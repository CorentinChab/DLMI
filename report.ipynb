{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24863eb9-a355-4b15-81fd-15bde50db9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb211dcc-a855-46fa-a089-7e138a999322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_IMAGES_PATH = 'train.h5'\n",
    "VAL_IMAGES_PATH = 'val.h5'\n",
    "TEST_IMAGES_PATH = 'test.h5'\n",
    "SEED = 0\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8b7eed-1342-40ae-9db5-4bdf10a878ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7add04e",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We defin here the preprocessing applied to the data. The most important is the normalization to avoid center different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c45b3-c623-4b47-bb90-3f78c943f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c40d3",
   "metadata": {},
   "source": [
    "# Hematodataset\n",
    "\n",
    "A dataset that allows us to speed up the loading of the keys by saving them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec68e09d-aa65-4709-a53b-5fe631b500be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "class HistoDataset(Dataset):\n",
    "    def __init__(self, path, transform, mode='train'):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        # Open file just to get the keys, then close\n",
    "        # Define a cache file for the keys\n",
    "        cache_path = f'{self.path}_keys.pkl'\n",
    "        if os.path.exists(cache_path):\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                self.ids = pkl.load(f)\n",
    "        else:\n",
    "            with h5py.File(path, 'r') as f:\n",
    "                self.ids = list(f.keys())\n",
    "            with open(cache_path, 'wb') as f:\n",
    "                pkl.dump(self.ids, f)\n",
    "        # File handle will be lazily initialized\n",
    "        self.file = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Lazily open the file if not already done\n",
    "        if self.file is None:\n",
    "            self.file = h5py.File(self.path, 'r')\n",
    "            \n",
    "        img_id = self.ids[idx]\n",
    "        # Load the image from the open file\n",
    "        img = torch.tensor(self.file[img_id]['img'][...])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            label = torch.tensor(self.file[img_id]['label'][...], dtype=torch.float32)\n",
    "            return img, label\n",
    "        return img, img_id\n",
    "\n",
    "    def __del__(self):\n",
    "        # Ensure the file is closed when the dataset is destroyed\n",
    "        if self.file is not None:\n",
    "            self.file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a7d376-aaf4-41a3-bd66-ac0812ff7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_ds = HistoDataset(TRAIN_IMAGES_PATH, train_transform, 'train')\n",
    "val_ds = HistoDataset(VAL_IMAGES_PATH, val_transform, 'train')\n",
    "test_ds = HistoDataset(TEST_IMAGES_PATH, val_transform, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6144b48b-7e11-45c3-b045-bbbb8cc0a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b98440",
   "metadata": {},
   "source": [
    "# 1st Experiment\n",
    "\n",
    "In this first experiment we try finetunning a resnet50 with the last layer being a simple linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c3db0-b68c-4d46-99ee-534795960b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/chabanolco/.conda/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/chabanolco/.conda/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(num_features, 1)\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89419925-c64e-4700-9186-a8fbcf95c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pos_weight_save = \"pos_weight.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d838bf0d-6865-4123-939b-7a36ba976d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5608e7af-f792-4f9a-8621-18d486694afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class balancing\n",
    "if not os.path.exists(pos_weight_save):\n",
    "    with h5py.File(TRAIN_IMAGES_PATH, 'r') as f:\n",
    "        labels = [f[img_id]['label'][()] for img_id in f.keys()]\n",
    "    pos_weight = (len(labels) - sum(labels)) / sum(labels)\n",
    "    with open(\"pos_weight.pkl\", \"wb\") as f:\n",
    "        pkl.dump(pos_weight, f)\n",
    "else: \n",
    "    with open(\"pos_weight.pkl\", \"rb\") as f:\n",
    "        pos_weight = pkl.load(f)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4478aee-a9c3-4630-a897-384bbfeec97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae5768-5548-4f47-a12e-31d18a73e94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b379f3fc94efb969107a729d753cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611819fffff74205b21280b27702f7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.3300 | Val Loss: 0.3830 | Val Acc: 0.8285\n",
      "New best model saved!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fbe235e013485181a62e4e1db0195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    progress = tqdm(train_loader, desc=f'Epoch {epoch+1} [Train]')\n",
    "    for inputs, labels in progress:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        progress.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        progress = tqdm(val_loader, desc=f'Epoch {epoch+1} [Val]')\n",
    "        for inputs, labels in progress:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss /= len(train_ds)\n",
    "    val_loss /= len(val_ds)\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "    # Update scheduler and check early stopping\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print('New best model saved!')\n",
    "    \n",
    "    if epoch - best_epoch >= PATIENCE:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e72dbb1-ef8e-46da-8231-71319e55eb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce7eb4d47224659af183e83d7a704d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/2658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test prediction\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "predictions = []\n",
    "ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, img_ids in tqdm(test_loader, desc='Predicting'):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy().astype(int)\n",
    "        predictions.extend(preds)\n",
    "        ids.extend(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd96f80d-8207-41f2-a002-c586324b7204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created!\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({'ID': [int(i) for i in ids], 'Pred': predictions})\n",
    "submission.set_index('ID', inplace=True)\n",
    "submission.to_csv('submission.csv')\n",
    "print('Submission file created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcbe3f",
   "metadata": {},
   "source": [
    "This submission file ended up lower than the baseline so we decided to push the finetunning further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209f553-75c3-4eb2-8a89-ec0e8a177be4",
   "metadata": {},
   "source": [
    "# LoRA Finetunining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b885e4",
   "metadata": {},
   "source": [
    "To make the Lora Finetuning, we replace the Conv2d layers with LaROConv2d layers and train only those layers (and the classsifier of course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57045b4d-9727-41e8-bb27-3843f8ec2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LoRAConv2d(nn.Module):\n",
    "    def __init__(self, conv_layer, rank=4):\n",
    "        super().__init__()\n",
    "        self.conv = conv_layer\n",
    "        self.rank = rank\n",
    "        \n",
    "        # Freeze original parameters\n",
    "        for param in self.conv.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Add LoRA parameters\n",
    "        in_channels = self.conv.in_channels\n",
    "        out_channels = self.conv.out_channels\n",
    "        # kernel_size = self.conv.kernel_size\n",
    "        \n",
    "        # LoRA parameters (using 1x1 convolutions)\n",
    "        self.lora_A = nn.Conv2d(\n",
    "            in_channels, rank, \n",
    "            kernel_size=1, stride=1,\n",
    "            padding=0, bias=False\n",
    "        )\n",
    "        self.lora_B = nn.Conv2d(\n",
    "            rank, out_channels, \n",
    "            kernel_size=1, stride=1,\n",
    "            padding=0, bias=False\n",
    "        )\n",
    "        \n",
    "        # Initialize parameters\n",
    "        nn.init.kaiming_uniform_(self.lora_A.weight, a=np.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        orig = self.conv(x)\n",
    "        lora = self.lora_B(self.lora_A(x))\n",
    "        # Adjust spatial dimensions if needed\n",
    "        if orig.shape[-2:] != lora.shape[-2:]:\n",
    "            lora = nn.functional.interpolate(\n",
    "                lora, size=orig.shape[-2:],\n",
    "                mode='bilinear', align_corners=False\n",
    "            )\n",
    "        return orig + lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e285575-304d-48cb-9094-81725f1990cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(model, rank=4):\n",
    "    # Apply LoRA to last 10 convolutional layers\n",
    "    layers_modified = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Replace with LoRA-conv\n",
    "            new_conv = LoRAConv2d(module, rank=rank)\n",
    "            parent = model\n",
    "            parts = name.split('.')\n",
    "            for part in parts[:-1]:\n",
    "                parent = getattr(parent, part)\n",
    "            setattr(parent, parts[-1], new_conv)\n",
    "            layers_modified += 1\n",
    "            # if layers_modified >= 10:  # Limit number of modified layers\n",
    "                # break\n",
    "    print(f\"Modified {layers_modified} layers\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d098aceb-b91a-416c-b1e0-e52ed659b933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified 53 layers\n"
     ]
    }
   ],
   "source": [
    "LORA_RANK = 8\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model = apply_lora(model, rank=LORA_RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0579968-a794-4946-99ea-caabb58a8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_features, 1)\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7ce71bc-9fe9-4d0e-8c62-630d179fcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class balancing\n",
    "if not os.path.exists(pos_weight_save):\n",
    "    with h5py.File(TRAIN_IMAGES_PATH, 'r') as f:\n",
    "        labels = [f[img_id]['label'][()] for img_id in f.keys()]\n",
    "    pos_weight = (len(labels) - sum(labels)) / sum(labels)\n",
    "    with open(\"pos_weight.pkl\", \"wb\") as f:\n",
    "        pkl.dump(pos_weight, f)\n",
    "else: \n",
    "    with open(\"pos_weight.pkl\", \"rb\") as f:\n",
    "        pos_weight = pkl.load(f)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaea4535-6273-44ec-8cbc-f8e975cde2f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameter: conv1.lora_A.weight\n",
      "Training parameter: conv1.lora_B.weight\n",
      "Training parameter: layer1.0.conv1.lora_A.weight\n",
      "Training parameter: layer1.0.conv1.lora_B.weight\n",
      "Training parameter: layer1.0.conv2.lora_A.weight\n",
      "Training parameter: layer1.0.conv2.lora_B.weight\n",
      "Training parameter: layer1.0.conv3.lora_A.weight\n",
      "Training parameter: layer1.0.conv3.lora_B.weight\n",
      "Training parameter: layer1.0.downsample.0.lora_A.weight\n",
      "Training parameter: layer1.0.downsample.0.lora_B.weight\n",
      "Training parameter: layer1.1.conv1.lora_A.weight\n",
      "Training parameter: layer1.1.conv1.lora_B.weight\n",
      "Training parameter: layer1.1.conv2.lora_A.weight\n",
      "Training parameter: layer1.1.conv2.lora_B.weight\n",
      "Training parameter: layer1.1.conv3.lora_A.weight\n",
      "Training parameter: layer1.1.conv3.lora_B.weight\n",
      "Training parameter: layer1.2.conv1.lora_A.weight\n",
      "Training parameter: layer1.2.conv1.lora_B.weight\n",
      "Training parameter: layer1.2.conv2.lora_A.weight\n",
      "Training parameter: layer1.2.conv2.lora_B.weight\n",
      "Training parameter: layer1.2.conv3.lora_A.weight\n",
      "Training parameter: layer1.2.conv3.lora_B.weight\n",
      "Training parameter: layer2.0.conv1.lora_A.weight\n",
      "Training parameter: layer2.0.conv1.lora_B.weight\n",
      "Training parameter: layer2.0.conv2.lora_A.weight\n",
      "Training parameter: layer2.0.conv2.lora_B.weight\n",
      "Training parameter: layer2.0.conv3.lora_A.weight\n",
      "Training parameter: layer2.0.conv3.lora_B.weight\n",
      "Training parameter: layer2.0.downsample.0.lora_A.weight\n",
      "Training parameter: layer2.0.downsample.0.lora_B.weight\n",
      "Training parameter: layer2.1.conv1.lora_A.weight\n",
      "Training parameter: layer2.1.conv1.lora_B.weight\n",
      "Training parameter: layer2.1.conv2.lora_A.weight\n",
      "Training parameter: layer2.1.conv2.lora_B.weight\n",
      "Training parameter: layer2.1.conv3.lora_A.weight\n",
      "Training parameter: layer2.1.conv3.lora_B.weight\n",
      "Training parameter: layer2.2.conv1.lora_A.weight\n",
      "Training parameter: layer2.2.conv1.lora_B.weight\n",
      "Training parameter: layer2.2.conv2.lora_A.weight\n",
      "Training parameter: layer2.2.conv2.lora_B.weight\n",
      "Training parameter: layer2.2.conv3.lora_A.weight\n",
      "Training parameter: layer2.2.conv3.lora_B.weight\n",
      "Training parameter: layer2.3.conv1.lora_A.weight\n",
      "Training parameter: layer2.3.conv1.lora_B.weight\n",
      "Training parameter: layer2.3.conv2.lora_A.weight\n",
      "Training parameter: layer2.3.conv2.lora_B.weight\n",
      "Training parameter: layer2.3.conv3.lora_A.weight\n",
      "Training parameter: layer2.3.conv3.lora_B.weight\n",
      "Training parameter: layer3.0.conv1.lora_A.weight\n",
      "Training parameter: layer3.0.conv1.lora_B.weight\n",
      "Training parameter: layer3.0.conv2.lora_A.weight\n",
      "Training parameter: layer3.0.conv2.lora_B.weight\n",
      "Training parameter: layer3.0.conv3.lora_A.weight\n",
      "Training parameter: layer3.0.conv3.lora_B.weight\n",
      "Training parameter: layer3.0.downsample.0.lora_A.weight\n",
      "Training parameter: layer3.0.downsample.0.lora_B.weight\n",
      "Training parameter: layer3.1.conv1.lora_A.weight\n",
      "Training parameter: layer3.1.conv1.lora_B.weight\n",
      "Training parameter: layer3.1.conv2.lora_A.weight\n",
      "Training parameter: layer3.1.conv2.lora_B.weight\n",
      "Training parameter: layer3.1.conv3.lora_A.weight\n",
      "Training parameter: layer3.1.conv3.lora_B.weight\n",
      "Training parameter: layer3.2.conv1.lora_A.weight\n",
      "Training parameter: layer3.2.conv1.lora_B.weight\n",
      "Training parameter: layer3.2.conv2.lora_A.weight\n",
      "Training parameter: layer3.2.conv2.lora_B.weight\n",
      "Training parameter: layer3.2.conv3.lora_A.weight\n",
      "Training parameter: layer3.2.conv3.lora_B.weight\n",
      "Training parameter: layer3.3.conv1.lora_A.weight\n",
      "Training parameter: layer3.3.conv1.lora_B.weight\n",
      "Training parameter: layer3.3.conv2.lora_A.weight\n",
      "Training parameter: layer3.3.conv2.lora_B.weight\n",
      "Training parameter: layer3.3.conv3.lora_A.weight\n",
      "Training parameter: layer3.3.conv3.lora_B.weight\n",
      "Training parameter: layer3.4.conv1.lora_A.weight\n",
      "Training parameter: layer3.4.conv1.lora_B.weight\n",
      "Training parameter: layer3.4.conv2.lora_A.weight\n",
      "Training parameter: layer3.4.conv2.lora_B.weight\n",
      "Training parameter: layer3.4.conv3.lora_A.weight\n",
      "Training parameter: layer3.4.conv3.lora_B.weight\n",
      "Training parameter: layer3.5.conv1.lora_A.weight\n",
      "Training parameter: layer3.5.conv1.lora_B.weight\n",
      "Training parameter: layer3.5.conv2.lora_A.weight\n",
      "Training parameter: layer3.5.conv2.lora_B.weight\n",
      "Training parameter: layer3.5.conv3.lora_A.weight\n",
      "Training parameter: layer3.5.conv3.lora_B.weight\n",
      "Training parameter: layer4.0.conv1.lora_A.weight\n",
      "Training parameter: layer4.0.conv1.lora_B.weight\n",
      "Training parameter: layer4.0.conv2.lora_A.weight\n",
      "Training parameter: layer4.0.conv2.lora_B.weight\n",
      "Training parameter: layer4.0.conv3.lora_A.weight\n",
      "Training parameter: layer4.0.conv3.lora_B.weight\n",
      "Training parameter: layer4.0.downsample.0.lora_A.weight\n",
      "Training parameter: layer4.0.downsample.0.lora_B.weight\n",
      "Training parameter: layer4.1.conv1.lora_A.weight\n",
      "Training parameter: layer4.1.conv1.lora_B.weight\n",
      "Training parameter: layer4.1.conv2.lora_A.weight\n",
      "Training parameter: layer4.1.conv2.lora_B.weight\n",
      "Training parameter: layer4.1.conv3.lora_A.weight\n",
      "Training parameter: layer4.1.conv3.lora_B.weight\n",
      "Training parameter: layer4.2.conv1.lora_A.weight\n",
      "Training parameter: layer4.2.conv1.lora_B.weight\n",
      "Training parameter: layer4.2.conv2.lora_A.weight\n",
      "Training parameter: layer4.2.conv2.lora_B.weight\n",
      "Training parameter: layer4.2.conv3.lora_A.weight\n",
      "Training parameter: layer4.2.conv3.lora_B.weight\n",
      "Training parameter: fc.1.weight\n",
      "Training parameter: fc.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Optimizer (only for trainable parameters)\n",
    "trainable_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora_' in name or 'fc' in name:\n",
    "        trainable_params.append(param)\n",
    "        print(f\"Training parameter: {name}\")\n",
    "        \n",
    "optimizer = torch.optim.Adam(trainable_params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "805fe7c7-3ee9-4a4b-b732-f531815b6574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7465731c084792ae076dd09b360023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6015c76bc644829d0b83deae16d556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.1441 | Val Loss: 0.1947 | Val Acc: 0.9261\n",
      "New best model saved!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f661b895f6bf48dc9008e4ddb6937aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecbc02d601b49e09f7d079fbf2456e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Train Loss: 0.0836 | Val Loss: 0.1961 | Val Acc: 0.9278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767337ec596b4973b23bfd169dd1e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbae534b34c47339096f45809c0c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Train Loss: 0.0702 | Val Loss: 0.2173 | Val Acc: 0.9292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f64762ef42492c819e476edef9fc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19e37c9981344638a5f512e4711775a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train Loss: 0.0634 | Val Loss: 0.2683 | Val Acc: 0.9098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcf9630543e4bd0a74dea48c4c9b5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac2d6d3297643bbbd22f0ea0f38f9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Train Loss: 0.0574 | Val Loss: 0.2252 | Val Acc: 0.9391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27380afb8d74c36a3e0183ad4ea9913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a689035f8c4e65acdc4f918d730bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Train Loss: 0.0547 | Val Loss: 0.2251 | Val Acc: 0.9295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ecf6ad99a84648a1183db54a8e51ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2b2bd90da34890ac7652d417910bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Train Loss: 0.0522 | Val Loss: 0.2178 | Val Acc: 0.9323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8e11e7fcad42d69d78ff3a50b44940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95b1de729a5411c875836abe638ddc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Train Loss: 0.0456 | Val Loss: 0.2194 | Val Acc: 0.9311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0a1de06dab4f088db44f06b2b6d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0328966d8bd49bf869572acb71ea2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Train Loss: 0.0445 | Val Loss: 0.2506 | Val Acc: 0.9305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9855cbe6483c415ea31b479cc4c95a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab5d09cd5c14da48ae7e6783b88a0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Train Loss: 0.0451 | Val Loss: 0.2391 | Val Acc: 0.9281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fad8b1e44249f1ba6875764d83d1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Train]:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0841c2b1accf430cb29b7589dd795649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Val]:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Train Loss: 0.0427 | Val Loss: 0.2380 | Val Acc: 0.9327\n",
      "Early stopping at epoch 11\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    progress = tqdm(train_loader, desc=f'Epoch {epoch+1} [Train]')\n",
    "    for inputs, labels in progress:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        progress.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        progress = tqdm(val_loader, desc=f'Epoch {epoch+1} [Val]')\n",
    "        for inputs, labels in progress:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss /= len(train_ds)\n",
    "    val_loss /= len(val_ds)\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    # Scheduler and early stopping\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_lora_model.pth')\n",
    "        print('New best model saved!')\n",
    "    \n",
    "    if epoch - best_epoch >= PATIENCE:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24554039-9cff-45c3-9242-c5c2fa24396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified 53 layers\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "# Generate predictions\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model = apply_lora(model, rank=8)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_features, 1)\n",
    ")\n",
    "model.load_state_dict(torch.load('best_lora_model.pth'))\n",
    "model.eval()\n",
    "predictions = []\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7d15433-7876-4a12-857b-e0a08068137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): LoRAConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (lora_A): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): LoRAConv2d(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): LoRAConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): LoRAConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): LoRAConv2d(\n",
       "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (lora_A): Conv2d(1024, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (lora_B): Conv2d(8, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(2048, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): LoRAConv2d(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(2048, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): LoRAConv2d(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_A): Conv2d(512, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_B): Conv2d(8, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b25871e2-6e03-4226-b225-a98ca1875672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37584e9392d64f41bb030bab325f10ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/2658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA submission file created!\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, img_ids in tqdm(test_loader, desc='Predicting'):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy().astype(int)\n",
    "        predictions.extend(preds)\n",
    "        ids.extend(img_ids)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({'ID': [int(i) for i in ids], 'Pred': predictions})\n",
    "submission.set_index('ID', inplace=True)\n",
    "submission.to_csv('lora_submission.csv')\n",
    "print('LoRA submission file created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacc608",
   "metadata": {},
   "source": [
    "This submission file ended up at 0.94"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
